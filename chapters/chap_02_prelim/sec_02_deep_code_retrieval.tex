\section{Deep Code Retrieval Problem}
\label{sec:deep-retrieval-problem}

The importance of traceability in modern software systems cannot be overstated. Traceability links that connect ``high-level" artifacts such as requirements and use cases to ``low-level'' artifacts written in code help to facilitate crucial components of the software development and maintenance cycle. For instance, linking requirements to code provides visibility into a system by enumerating what has been implemented, whereas linking requirements to test cases helps to provide an indication that the software is functioning as expected. Additionally, the establishment of trace links aids in facilitating a broad set of developer activities including code comprehension, change impact analysis, and compliance validation~\citep{Cleland-Huang:Springer'12}.  In certain software domains, such as those involving safety critical systems, traceability is necessarily \textit{mandated} by regulatory bodies in order to properly demonstrate the safe functioning of a system~\citep{Nejati:IST'12,Rempel:ICSE'14,Cleland-Huang:ICSE'10,Mader:Soft'13}. Furthermore, traceability is increasingly used to help ensure the \textit{security} of a given system~\citep{Nhlabatsi:SST'15}. For example, our industrial partners at Cisco Systems, Inc. require that security-critical requirements are verified by a dedicated group of analysts to avoid software threats and ensure best practices. 

Unfortunately, despite its importance, software traceability is, by its nature, an inherently difficult and error prone task~\citep{Cleland-Huang:FOSE'14,Mahmoud:ICPC'12,Mader:Soft'13}. This difficulty primarily stems from the need to bridge a logical abstraction gap that exists between different software artifacts, such as requirements written in natural language and code written in ``lower-level'' programming languages.  %Thus, bridging this abstraction gap typically requires developers or analysts with expertise related to a given software system to manually comprehend these artifacts and decipher meaningful relationships among them.  
Given the effort required to establish and evolve effective trace links, it is often too costly to manually establish them outside of regulated domains, and in practice the quality of mandated links are often questionable~\citep{Cleland-Huang:FSE'14}.  

The inherent difficulty in establishing trace links has lead to research on automated techniques for modeling, establishing, and evolving trace links that primarily rely upon information retrieval (IR)~\citep{Lucia:ICSM'04,Dekhtyar:RE'07,Asuncion:ICSE'10,McMillan:TEFSE'09,Gethers:ICSM'11,DeLucia:ASE'08,DeLucia:EMSE'09,Mahmoud:ICPC'12,Antoniol:ICSE'00,Marcus:ICSE'03,Mills:ICSME18,Jiang:ASE'08,Kuang:SANER'17} and machine learning (ML)~\citep{Mahmoud:RE'16,Guo:MSR'16,Asuncion:ICSE'10,Spanoudakis:SEKE'03,Falessi:EMSE17} techniques which retrieve or predict trace links based upon textual similarity metrics.  However, in large part, current automated approaches for traceability often trade precision for completeness and vice versa, making them difficult to adopt in practice. We observe three major shortcomings of current automated techniques that contribute to their limited effectiveness:

\noindent{\textbf{1) Limited Measures of Artifact Similarity:}} Existing techniques for trace link recovery tend to use a single textual similarity metric to draw relationships between artifacts. This is problematic for several reasons. Perhaps most importantly, it is often difficult or impossible to determine how well a technique that uses a given similarity measure will function on artifacts from a new project without any pre-existing trace links. This so-called ``cold-start'' problem is due to the fact that existing IR/ML techniques for measuring textual similarity often need to be calibrated on a subset of "ground-truth" artifact pairs with pre-existing links. This makes performance of these techniques difficult to predict when applied to new datasets. Furthermore, in practice industrial projects often lack pre-existing trace links, as confirmed by our  partners at Cisco. Thus, while certain techniques have been shown to perform well on research benchmarks, the efficacy of a similarity measure is often tightly coupled to the underlying semantics of software artifact text~\citep{Lohar:FSE'13,Guo:ICSE'17,Biggerstaff:ACM'94}, and to the configuration of the corresponding IR/ML technique~\citep{Oliveto:ICPC'10}. 

Using only a single textual similarity metric also needlessly restricts the predictive power of a traceability technique. Past work has illustrated the orthogonality of different similarity measures~\citep{Oliveto:ICPC'10}, suggesting that combining \textit{several} different measures could lead to more accurate and robust techniques that function \textit{consistently} well when applied to new projects without pre-existing links.

\noindent{\textbf{2) Inability to Effectively Capture Developer Feedback:}} The rapid pace of modern agile development practices often results in crucial knowledge about a software system being siloed within the expertise of individual developers. Thus, one unstructured development artifact that has gone underutilized by past techniques is \textit{developer feedback}. When an automated traceability model is uncertain about particular trace link pairs, developers can provide critical feedback to help improve trace link inference.

\noindent{\textbf{3) Limited View of Interactions Between Artifacts}}
Existing automated traceability approaches are typically tailored to establish relationships between pairs of specific types of artifacts (\eg user stories and class files). However, information pertaining to the relationship of one type of artifact pair may be contained within other related artifacts. For example, if a piece of source code is linked to a given requirement through textual similarities, and this source code is also intrinsically linked to test code via method calls, then it is likely the requirement is also linked to the test code. However, in this situation, it may be difficult for a textual similarity metric to link the requirements and test code, due to limited test documentation, for example. Thus, in this way, established relationships between certain artifacts may influence the probability of other artifact relationships. In this paper we refer to these phenomena as \textit{transitive links}. Existing techniques generally cannot model such interactions between artifacts.

The limitations discussed above stem from both technical and practical limitations of existing traceability techniques, and surfaced during our development of an automated traceability approach in close collaboration with Cisco Systems. In this paper we introduce a novel technique that overcomes these limitations by constructing a Hierarchical Bayesian Network for inferring a set of candidate trace links. The model that underlies our approach is capable of deriving the probability that a trace link exists between two given artifacts by combining information from multiple measures of textual similarity, while simultaneously modeling transitive relationships and accounting for developer expertise.  We implemented our approach, called \Comet (Hierarchi\textbf{C}al Pr\textbf{O}babilistic \textbf{M}odel for Softwar\textbf{E} \textbf{T}raceability), in both an extensible Python library and as a plugin for the popular Jenkins CI/CD system.  In an extensive set of empirical experiments we illustrate that \Comet is able to outperform the median precision of \textit{optimally configured} baseline techniques by $\approx$5\% across subjects and $\approx$14\% in the best case. Given that optimal configuration is typically not possible in practice, this illustrates that given a project with no pre-existing trace links, \Comet is likely to perform significantly better than most existing IR/ML techniques. Additionally, we show \Comets potential for integration into the workflows of development teams at Cisco. In summary, this paper's contributions are as follows:

\begin{itemize}
	\item{The derivation of a Hierarchical Bayesian Network (HBN) for inferring a candidate set of trace links;}	
	\item{An implementation of this model, called \Comet, as both an extensible Python library and a Jenkins plugin that has been deployed for testing with our industrial partners at Cisco;}
	\item{An extensive evaluation of \Comet on both open source projects and two industrial datasets from one industrial software project, including feedback from professional developers at a major telecommunication software company;}
	\item{An open source, commercial-grade traceability benchmark, developed in coordination with our industrial partner, for the benefit of the research community;}
	\item{An online appendix, including our open source implementation of \Comet and evaluation data for reproducibility~\cite{appendix}}.
\end{itemize}

\subsection{Formalization}

Our goal is to design a model that captures meaningful information regarding logical relationships between software artifacts, and then use this model to infer a set of candidate trace links. More specifically, given a set of source artifacts $S$ (\eg requirements, use cases) such that $S = \{S_{1},S_{2},\ldots S_{n}\}$ and a set of target artifacts $T$ (\eg source code files, test cases) such that $T = \{T_{1},T_{2},\ldots T_{n}\}$, we aim to infer whether a trace link $L$ exists between all possible pairs of artifacts in $S$ and $T$ such that $L = \{(s,t) | s\in S, t\in T, s\leftrightarrow t\}$ where each pair of artifacts $s$ and $t$ are said to be logical trace links.


\subsection{The Probabilistic Nature of Software Traceability}
\david{The probabilistic nature of software retrieval!}
The process of building software is not inherently deterministic, and is instead the result of decisions made by engineers over prolonged periods of time that may be hard to predict. Developer decisions related to nearly every observable phenomenon in modern software development are influenced by a combination of multiple factors. For instance, the presence of a functional bug may be influenced by the quality of related requirements, implementation constraints imposed by a given programming language~\citep{Ray:CACM'17}, or the change-proneness of underlying APIs~\citep{Linares-Vasquez:FSE'13}. Given that such factors are often hard to predict, there is a clear sense of randomness inherent to the software development process. Similarly, the existence of trace links among software artifacts is also likely to be influenced by several different effectively \textit{random} factors.  

These factors could include textual similarities between artifacts, programmatic associations between pieces of code, or even abstract notions of similarity held by expert developers.  For example, the textual quality of requirements or identifiers in code are typically a function of several factors such as the fluency and writing style of the author and the familiarity of key phrases chosen for identifiers \citep{Dasgupta:ICSME'13}. This may lead to variable names that may be perfectly clear to one engineer being indecipherable to another.  \textit{From this view point, the existence of trace links between software artifacts can be thought of as an inherently a probabilistic phenomenon}.

\subsection{Traceability as a Bayesian Inference Problem}

Hence, in order to effectively model trace links among software artifacts, it is necessary to model a collection of random factors that influence \textit{the probability that a trace link exists}. Thus, the process of deriving trace links can be modeled as a \textit{Bayesian inference} problem, wherein a probability distribution representing the existence of a trace link between two artifacts can be inferred. As we illustrate, by modeling the trace link recovery problem in a probabilistic manner, we are able to construct an an automated approach that largely overcomes the typical drawbacks discussed in \secref{sec:intro} \david{Fix this reference}. To understand this context, let us consider the general definition of Bayes' Theorem:

\marginnote{
\begin{equation}
P(H|O) = \frac{P(O|H)\cdot P(H)}{P(O)}
\end{equation}
}

\noindent where $H$ is a hypothesis regarding some phenomenon, $O$ is a set of observations that provide some information about the hypothesis, and where our goal is to infer or estimate the probability that our hypothesis is true $P(H|O)$, which is called the \textit{posterior probability distribution}, or more simply the \textit{posterior}. However, a given hypothesis is rarely made in a vacuum, and one typically holds some \textit{prior belief} as to the probability that is being inferred.  This prior belief is modeled as a probability distribution $P(H)$, which we will simply refer to as the \textit{prior}, and can be influenced by a number of factors. In order for the posterior to be inferred from a set of observations, these must be modeled in a probabilistic manner. This is the purpose of the \textit{likelihood} $P(O|H)$, which is a probability distribution that is derived purely from observed data. Thus, in Bayesian inference initial beliefs are represented as the prior, observations are modeled as the likelihood and the final beliefs are represented by the posterior. This posterior probability distribution can be \textit{inferred} via one of several existing statistical inference techniques. In framing the problem of inferring trace links as a Bayesian problem, we consider our hypothesis to be whether a given trace link exists between a single source artifact $S_x$ and a single target artifact $T_y$. Given the nature of trace links (\eg a link either does or does not exist) we can model our prior as a distribution on the interval $[0,1]$, where 1 indicates the presence of a link and 0 indicates an absence. 

\subsection{A Hierarchical Bayesian Network for Traceability}

In the context of this paper, we will consider our \textit{likelihood} (observations) to be the binary indication that a link exists according to a set of textual similarity measures and an empirically derived threshold value. However, given that we aim to model multiple factors that might influence traceability, our model employs multiple \textit{priors}, called \textit{hyperpriors}, forming a Hierarchical Bayesian Network (HBN). In this work, we consider three priors corresponding to the three factors we wish to model: (i) a normalized set of diverse textual similarity measures, (ii) developer expertise, and (iii) transitive trace links. We assign each of these priors an initial probability distribution, which is then influenced and estimated based upon observable data (e.g. a developer confirming or denying a trace link). Once this network is established, the \textit{posterior} can be computed via one of several estimation techniques. By modeling these three information sources, our technique is able to largely overcome the limitations enumerated in \secref{sec:intro} \david{Fix this reference}. HBNs are also highly extensible via adjustments to the prior(s). Thus our defined model be capable of adapting to advancements in textual similarity measures or considering new development artifacts from future development workflows.
