\chapter{Introduction} % The asterisk * leaves out this chapter from the table of contents
\label{ch:intro}


Software engineering (SE) research investigates questions pertaining to the design, development, maintenance, testing, and evolution of software systems. As software continues to pervade a wide range of industries, both open- and closed-source code repositories have grown to become unprecedentedly large and complex. This has resulted in an increase of unstructured, unlabeled, yet important data including requirements, design documents, source code files, test cases, and defect reports. Previously, the software engineering community has applied canonical machine learning (ML) techniques to identify patterns and unique relationships within this data to automate or enhance many tasks typically performed manually by developers. Unfortunately, the process of implementing ML techniques can be a tedious exercise in careful feature engineering, wherein researchers experiment with identifying salient attributes of data that can be leveraged to help solve a given problem or automate a given task.

However, with recent improvements in computational power and the amount of memory available in modern computer architectures, an advancement to traditional ML approaches has arisen called Deep Learning (DL). Deep learning represents a fundamental shift in the manner by which machines learn patterns from data by \textit{automatically} extracting salient features for a given computational task as opposed to relying upon human intuition. Deep Learning approaches are characterized by architectures comprised of several layers that perform mathematical transformations on data passing through them. These transformations are controlled by sets of learnable parameters that are adjusted using a variety of learning and optimization algorithms. These computational layers and parameters form models that can be trained for specific tasks by updating the parameters according to a model's performance on a set of training data. Given the immense amount of structured and unstructured data in software repositories that are likely to contain hidden patterns, DL techniques have ushered in advancements across a range of tasks in software engineering research including automatic program repair~\citep{Tufano2018}, code suggestion~\citep{Gu2018}, defect prediction~\citep{Wang2016}, malware detection \cite{Li2018}, feature location~\citep{Corley2015}, among many others~\citep{Ma2018, Wan2018, Liu2018, White2016, Xu2016, Guo2017, Tian2018a, Liu2017}. A recent report from the 2019 NSF Workshop on Deep Leaning \& Software Engineering has referred to this area of work as Deep Learning for Software Engineering (DL4SE)~\citep{dlse19-report}. 

The applications of DL to improve and automate SE tasks points to a clear synergy between ongoing research in SE and DL. However, in order to effectively chart the most impactful path forward for research at the intersection of these two fields, researchers need a clear map of what has been done, what has been successful, and what can be improved. %
In an effort to map and guide research at the intersection of DL and SE, we conducted a systematic literature review (SLR) to identify and systematically enumerate the synergies between the two research fields. As a result of the analysis performed in our SLR, we synthesize a detailed \textit{research roadmap} of past work on DL techniques applied to SE tasks\footnote{It should be noted that another area, known as Software Engineering for Deep Learning (SE4DL), which explores improvements to engineering processes for DL-based systems, was also identified at the 2019 NSF workshop. However, the number of papers we identified on this topic was small, and mostly centered around emerging testing techniques for DL models. Therefore, we reserve a survey on this line of research for future work.} (\ie DL4SE), complete with identified open challenges and best practices for applying DL techniques to SE-related tasks and data. Additionally, we analyzed the impacts of these DL-based approaches and discuss some observed concerns related to the potential reproducibility and replicability of our studied body of literature. %

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Paragraph1: Motivation
\newthought{This dissertation} explores the usage of a mathematical structure that assess the causal effect of automation process in the context of Software Engineering. Such mathematical structure embodies the causal calculus to perform estimations of software variables affecting other variables. However, the software variables under analysis are not coming from the classical perspective of software engineering but from the field where Software Engineering is generated by Artificial Intelligence mechanism. This field is introduced as \textit{Artificial Software Engineering} (\asofte). In order to \textit{Artificial Software Engineering} achieve understandability (or interpretability in a Machine Learning context). It is required to adapt, formalize, and evaluate Causal Inference concepts or causal mathematical structures that help aid to uncover causal effects. Therefore, we need a causal artificial software structure at the interface of causality and artificial software engineering.  

% Paragraph2: What is the specific problem?
Although Causal Calculus has been introduced since the 80s, there no exist a formalization of a causal artificial software structure...  

% Paragraph3: What is the main contribution of the dissertation?
This dissertation poses a causal structure for the problem of deep code retrieval and deep code interpretability...

% Paragraph4: Differences of what I am doing and others have done

% Paragraph5: The structure of the dissertation.





%------------------------------------------------
\section{A Motivating Example}

%------------------------------------------------
\section{Terminology}

\subsection{Interpretability}
Neural Language Models (NLM) are increasingly being used in Software Engineering as \textit{Code Generators} showing promising results in generating correct and realistic code. Intepretability represents one of the major challenge limiting the deployment and usage of these models in practice, since the causal relationship between the input and output is often unclear and no cues are provided informing what influenced the generation of a specific snippet of code. In this patent we propose \codeSeqRational, a framework that allows to extract practical interpretability insights for NLM-based systems for code-related tasks. Our approach is based on a greedy algorithm which extracts the smallest subset of tokens (rationales) from the input sufficient to predict each token in the output. Next, these rationales are mapped into human-interpretable concepts by a set of mapping functions, which assign tokens to a set of categories. These include code-specific categories (\ie structural and identifiers extracted with a code parser), as well as natural language categories (\eg verbs and nouns extracted with a NL context-free grammar parser). Finally, tokens are grouped into location-aware scopes. This infrastructure allows researchers and practitioners to debug NLM outputs as well as further optimize the input to these models evaluating the importance of each token, category, or scope.