\section{Discussion}
\label{sec:discussion-hbn}

\subsection{Threats to Validity}
\label{sub:threats}
Similar to past work on automated trace link recovery approaches~\citep{Guo:ICSE'17}, our work exhibits two main threats to validity. The first of these threats is to external validity. We utilize a limited number of systems to carry out our evaluation of \Comet, and thus it is possible that our results may not generalize to other systems. However, the systems utilized in our evaluation have been widely used in past work, and are of varying sizes and domains. We also examine one industrial grade open source project developed by our partner.
	
The second threat to validity that affects experimental evaluation concerns construct validity, and more specifically, the accuracy of the ground truth for our subjects, and our implementation of the DL approach by Guo \etal~\citep{Guo:ICSE'17}. We cannot guarantee that the ground truth links for all of subjects are perfectly accurate. However, the ground truth sets for the CoEST datasets have been accepted by several pieces of prior work~\citep{Antoniol:e,Cleland-Huang:TSE'03,Poshyvanyk:TEFSE'11,Gethers:ICSM'11}. The ground truth for LibEST was derived by a team of the authors, and was validated with the help of industrial developers working on the project (see Sec. \ref{sub:exp-context}). We re-implemented Guo \etal's DL approach closely following the details of the paper, although a full replication was not possible due to previous use of  proprietary industrial dataset. We will release our code~\citep{appendix} for this approach to aid in reproducibility. Another potential threat to validity is that our simulation of developer feedback in answering RQ$_2$ is not representative of real feedback. Due to constraints on developers time, we could not use real feedback, however, we believe simulating a small number of links using the ground truth, complete with error rates, represents a reasonable approximation.

\subsection{Related Work}
\label{sub:related-work}

We focus our discussion of related work on prior techniques that have, in limited contexts, (i) considered novel or hybird textual similarity measures, (ii) modeled the effects of multiple types of artifacts, or (iii) incorporated developer expertise. We then conclude with a statement distilling \Comets novelty.

\noindent{\textbf{Novel/Hybird Textual Similarity Measures:}} Guo \etal~\citep{Guo:ICSE'17} proposed an approach for candidate trace link prediction that uses a semantically enhanced similarity measure based on Deep Learning (DL) techniques. However, unlike \Comet, this technique requires pre-existing trace links in order to train the DL classifier.  In contrast, \Comet does not require known links for the projects it is applied to, but rather requires a project to serve as a tuning set. We show that \Comet performs well when tuned and tested on different datasets, outperforming Guo \etals DL-based approach when it is trained in a similar manner. Gethers \etal~\citep{Gethers:ICSM'11}, implemented an approach that is capable of combining information from canonical IR techniques (\ie VSM, Jensen-Shannon) with Topic Modeling techniques. However, their approach can only combine two IR/ML techniques, whereas \Comet can combine and leverage the observations from several IR/ML techniques, and combine this with other information such as expert feedback and transitive links. 

\noindent{\textbf{Modeling of Multiple Artifacts:}} Rath \etal~\citep{Rath:ICSE'18} recently explored linking nontraditional information including issues and commits, and Cleland-Huang \etal~\cite{Cleland-Huang:ICSE'10} have investigated linking regulatory codes to product level requirements.  \Comets model has the potential to improve trace link recovery in these scenarios both through its more robust modeling of textual similarity, and through incorporation of transitive link information. Furtado \etal~\cite{Furtado:RE'16}, explored traceability in the context of agile development, and Nishikawa \etal~\cite{Nishikawa:ICSME'15} first explored the use of transitive links in a deterministic traceability model. Additionally, Kuang \etal used the closeness of code dependencies, to help improve IR-based traceability recovery~\cite{Kuang:SANER'17}. However, none of these approaches is capable of incorporating transitive links while also considering combined textual similarity metrics and developer feedback.

\noindent{\textbf{Incorporation of Developer Expertise:}} De Lucia \etal \citep{DeLucia:ICSM'06} and Hayes \etal~\citep{Hayes:TSE'06} analyzed approaches that use relevance feedback to improve trace link recovery. However, these approaches are either tied to a particular type of model (such as TF-IDF~\citep{DeLucia:ICSM'06}), or require knowledge of the underlying model to function optimally. In contrast, \Comet implements a lightweight, likert-based feedback collection mechanism that we illustrate can improve link accuracy even when only a small amount of feedback is collected.
 
\noindent{\textbf{Summary of Advancement over Prior Work:}} \Comets features facilitate its application to projects without any pre-existing trace links, and as our evaluation illustrates, allow it to perform consistently well across datasets. \Comet is able to combine information from transitive links with both robust textual similarity measures and lightweight developer feedback for improved accuracy. While some aspects of \Comets approach have been considered in limited contexts in prior work -- such as developer feedback~\citep{DeLucia:ICSM'06,Hayes:TSE'06} and restricted combinations of IR/ML techniques~\citep{Gethers:ICSM'11} -- there has never been a framework capable of combining all these aspects in a holistic approach. Our evaluation illustrates that \Comets holistic HBN is able to outperform baseline techniques on average.

