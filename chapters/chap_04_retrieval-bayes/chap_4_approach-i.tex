\chapter{Inferring Trace Links with \break a Hierarchical Bayesian Network}
\label{ch:hbn}

% 0. A General Introduction

The importance of traceability in modern software systems cannot be overstated. Traceability links that connect ``high-level" artifacts such as requirements and use cases to ``low-level'' artifacts written in code help to facilitate crucial components of the software development and maintenance cycle. For instance, linking requirements to code provides visibility into a system by enumerating what has been implemented, whereas linking requirements to test cases helps to provide an indication that the software is functioning as expected. Additionally, the establishment of trace links aids in facilitating a broad set of developer activities including code comprehension, change impact analysis, and compliance validation~\citep{Cleland-Huang:Springer'12}.  In certain software domains, such as those involving safety critical systems, traceability is necessarily \textit{mandated} by regulatory bodies in order to properly demonstrate the safe functioning of a system~\citep{Nejati:IST'12,Rempel:ICSE'14,Cleland-Huang:ICSE'10,Mader:Soft'13}. Furthermore, traceability is increasingly used to help ensure the \textit{security} of a given system~\citep{Nhlabatsi:SST'15}. For example, our industrial partners at Cisco Systems, Inc. require that security-critical requirements are verified by a dedicated group of analysts to avoid software threats and ensure best practices. 

Unfortunately, despite its importance, software traceability is, by its nature, an inherently difficult and error prone task~\citep{Cleland-Huang:FOSE'14,Mahmoud:ICPC'12,Mader:Soft'13}. This difficulty primarily stems from the need to bridge a logical abstraction gap that exists between different software artifacts, such as requirements written in natural language and code written in ``lower-level'' programming languages.  %Thus, bridging this abstraction gap typically requires developers or analysts with expertise related to a given software system to manually comprehend these artifacts and decipher meaningful relationships among them.  
Given the effort required to establish and evolve effective trace links, it is often too costly to manually establish them outside of regulated domains, and in practice the quality of mandated links are often questionable~\citep{Cleland-Huang:FSE'14}.  

The inherent difficulty in establishing trace links has lead to research on automated techniques for modeling, establishing, and evolving trace links that primarily rely upon information retrieval (IR)~\citep{Lucia:ICSM'04,Dekhtyar:RE'07,Asuncion:ICSE'10,McMillan:TEFSE'09,Gethers:ICSM'11,DeLucia:ASE'08,DeLucia:EMSE'09,Mahmoud:ICPC'12,Antoniol:ICSE'00,Marcus:ICSE'03,Mills:ICSME18,Jiang:ASE'08,Kuang:SANER'17} and machine learning (ML)~\citep{Mahmoud:RE'16,Guo:MSR'16,Asuncion:ICSE'10,Spanoudakis:SEKE'03,Falessi:EMSE17} techniques which retrieve or predict trace links based upon textual similarity metrics.  However, in large part, current automated approaches for traceability often trade precision for completeness and vice versa, making them difficult to adopt in practice. We observe three major shortcomings of current automated techniques that contribute to their limited effectiveness:

\noindent{\textbf{1) Limited Measures of Artifact Similarity:}} Existing techniques for trace link recovery tend to use a single textual similarity metric to draw relationships between artifacts. This is problematic for several reasons. Perhaps most importantly, it is often difficult or impossible to determine how well a technique that uses a given similarity measure will function on artifacts from a new project without any pre-existing trace links. This so-called ``cold-start'' problem is due to the fact that existing IR/ML techniques for measuring textual similarity often need to be calibrated on a subset of "ground-truth" artifact pairs with pre-existing links. This makes performance of these techniques difficult to predict when applied to new datasets. Furthermore, in practice industrial projects often lack pre-existing trace links, as confirmed by our  partners at Cisco. Thus, while certain techniques have been shown to perform well on research benchmarks, the efficacy of a similarity measure is often tightly coupled to the underlying semantics of software artifact text~\citep{Lohar:FSE'13,Guo:ICSE'17,Biggerstaff:ACM'94}, and to the configuration of the corresponding IR/ML technique~\citep{Oliveto:ICPC'10}. 

Using only a single textual similarity metric also needlessly restricts the predictive power of a traceability technique. Past work has illustrated the orthogonality of different similarity measures~\citep{Oliveto:ICPC'10}, suggesting that combining \textit{several} different measures could lead to more accurate and robust techniques that function \textit{consistently} well when applied to new projects without pre-existing links.

\noindent{\textbf{2) Inability to Effectively Capture Developer Feedback:}} The rapid pace of modern agile development practices often results in crucial knowledge about a software system being siloed within the expertise of individual developers. Thus, one unstructured development artifact that has gone underutilized by past techniques is \textit{developer feedback}. When an automated traceability model is uncertain about particular trace link pairs, developers can provide critical feedback to help improve trace link inference.

\noindent{\textbf{3) Limited View of Interactions Between Artifacts}}
Existing automated traceability approaches are typically tailored to establish relationships between pairs of specific types of artifacts (\eg user stories and class files). However, information pertaining to the relationship of one type of artifact pair may be contained within other related artifacts. For example, if a piece of source code is linked to a given requirement through textual similarities, and this source code is also intrinsically linked to test code via method calls, then it is likely the requirement is also linked to the test code. However, in this situation, it may be difficult for a textual similarity metric to link the requirements and test code, due to limited test documentation, for example. Thus, in this way, established relationships between certain artifacts may influence the probability of other artifact relationships. In this paper we refer to these phenomena as \textit{transitive links}. Existing techniques generally cannot model such interactions between artifacts.

The limitations discussed above stem from both technical and practical limitations of existing traceability techniques, and surfaced during our development of an automated traceability approach in close collaboration with Cisco Systems. In this paper we introduce a novel technique that overcomes these limitations by constructing a Hierarchical Bayesian Network for inferring a set of candidate trace links. The model that underlies our approach is capable of deriving the probability that a trace link exists between two given artifacts by combining information from multiple measures of textual similarity, while simultaneously modeling transitive relationships and accounting for developer expertise.  We implemented our approach, called \Comet (Hierarchi\textbf{C}al Pr\textbf{O}babilistic \textbf{M}odel for Softwar\textbf{E} \textbf{T}raceability), in both an extensible Python library and as a plugin for the popular Jenkins CI/CD system.  In an extensive set of empirical experiments we illustrate that \Comet is able to outperform the median precision of \textit{optimally configured} baseline techniques by $\approx$5\% across subjects and $\approx$14\% in the best case. Given that optimal configuration is typically not possible in practice, this illustrates that given a project with no pre-existing trace links, \Comet is likely to perform significantly better than most existing IR/ML techniques. Additionally, we show \Comets potential for integration into the workflows of development teams at Cisco. In summary, this paper's contributions are as follows \david{Fix this contributions to be more precise for the chapter}:

\begin{itemize}
	\item{The derivation of a Hierarchical Bayesian Network (HBN) for inferring a candidate set of trace links;}	
	\item{An implementation of this model, called \Comet, as both an extensible Python library and a Jenkins plugin that has been deployed for testing with our industrial partners at Cisco;}
	\item{An extensive evaluation of \Comet on both open source projects and two industrial datasets from one industrial software project, including feedback from professional developers at a major telecommunication software company;}
	\item{An open source, commercial-grade traceability benchmark, developed in coordination with our industrial partner, for the benefit of the research community;}
	\item{An online appendix, including our open source implementation of \Comet and evaluation data for reproducibility~\cite{appendix}}.
\end{itemize}

%------------------------------------------------

\input{chapters/chap_04_retrieval-bayes/sec_01_approach}

%------------------------------------------------

\input{chapters/chap_04_retrieval-bayes/sec_02_design}

%------------------------------------------------

\input{chapters/chap_04_retrieval-bayes/sec_03_results}

%------------------------------------------------

\input{chapters/chap_04_retrieval-bayes/sec_04_discussion}



